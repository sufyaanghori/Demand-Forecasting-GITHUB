{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2669146,"sourceType":"datasetVersion","datasetId":55151}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brazilian E-commerce Dataset Analysis\n\n## Project Overview: \n\nThis data analysis project explores a public dataset of e-commerce orders from Olist. Olist is a prominent online e-commerce platform connecting merchants to the main marketplaces of Brazil. The dataset comprises 100,000 orders between 2016 and 2018, offering valuable information on various aspects of the customer journey, including order status, pricing, payment, and customer reviews.\n\nPresented by Olist, this dataset underscores the platform's success in streamlining e-commerce operations for merchants across Brazilian marketplaces. Olist facilitates seamless connections between merchants and consumers through innovative solutions, fostering a unified and efficient e-commerce ecosystem.\n\nThis analysis will delve deeper into understanding the customer journey, comparing seller orders and their delivery times, and analyzing payment methods and payment installment patterns across different regions. Lastly, it will conduct an RFM (Recency, Frequency, Monetary) analysis, and by using this technique marketers can tailor their marketing strategies accordingly. We can easily analyze the segmentation to reveal the loyal customers and the retention customers. By unlocking the power of Brazilian e-commerce through data-driven insights, marketers can reach important findings that can contribute to strategic decision-making and drive further growth in the e-commerce landscape.\n\n\n## Table of Contents\n\n* [Project Overview](#project-overview)\n* [Data Sources](#data-sources)\n* [Tools](#tools)\n* [Data Cleaning & Preparation](#data-cleaning-preparation)\n* [Exploratory Data Analysis](#exploratory-data-analysis)\n* [Data Analysis](#data-analysis)\n* [Results&Findings](#results/findings)\n* [Recommendations](#recommendations)\n* [Limitations](#limitations)\n* [References](#references)\n\n## Tools\n\n- Excel- Data Cleaning\n   - [Download here] (https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)\n- PostgreSQL- Data Analysis\n- Python- Data Visualisation\n## Data Cleaning/Preparation\n\nIn the initial data preparation phase, the following tasks were performed:\n1. Data Loading and inspection.\n2. Data cleaning and formatting.\n\n## Database Schema (ERD)\n\n![ERD pgerd](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/a305011e-80b8-4e17-bcc7-a310872d9b06)\n\nAs can be depicted from the schema, the database contains eight tables. These tables are orders, sellers, order_items, order_reviews, order_payments, products, customers and the product_category_name_translation. We will examine each table independently and conduct pre-processing to minimize excess space usage.","metadata":{}},{"cell_type":"markdown","source":"## EDA( Exploratory Data Analysis)\n\n**The Order Item Table, sourced from the \"orders_data\", consists of the following columns:**\n\n- order_id: A unique identifier for each order.\n- order_item_id: A sequential number indicating the position of an item within the order.\n- product_id: A unique identifier for each product.\n- seller_id: A unique identifier for each seller.\n- shipping_limit_date: The deadline set by the seller for handing over the order to the logistics partner.\n- price: The price of the item.\n- freight_value: The freight cost associated with the item. If an order contains multiple items, the freight cost is divided among them.","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:37:38.313206Z","iopub.execute_input":"2024-04-07T09:37:38.314132Z","iopub.status.idle":"2024-04-07T09:37:38.325668Z","shell.execute_reply.started":"2024-04-07T09:37:38.314091Z","shell.execute_reply":"2024-04-07T09:37:38.323667Z"}}},{"cell_type":"markdown","source":"We start with viewing the first few rows of the table using the limit function from PostgreSQL.\n\n```SQL\nselect * from order_items limit 10;\n```\n![Order_items_table](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/e4dc81e7-73b7-45f7-85fa-d62f6d691159)\n\n**The Product Table contains the following columns:**\n\n- product_id: A unique identifier for each product.\n- product_category_head: The root category of the product, originally in Portuguese.\n- product_name_length: The length of the product name in characters.\n- product_description_length: The length of the product description in characters.\n- product_photos_qty: The number of photos published for the product.\n- product_weight_g: The weight of the product measured in grams.\n- product_length_cm: The length of the product measured in centimeters.\n- product_height_cm: The height of the product measured in centimeters.\n- product_width_cm: The width of the product measured in centimeters.\n\nNext, we view the first few rows of the table using the limit from PostgreSQL.\n\n```SQL\nselect * from products limit 10;\n```\n![products_table1](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/7b675f09-fec1-49b5-a45f-fa8fb0b8a15a)\n\n![products_table2](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/54fbb816-018a-4616-8b3e-9f74c0551fa3)\n\n\n**The Product Category Info Table contains the following columns:**\n\n- product_category_name: The category name was originally in Portuguese.\n- product_name_english: The category name is translated into English.\n\nWe view the first few rows of the table using the limit from PostgreSQL.\n\n```SQL\nselect * from product_category_name_translation limit 10;\n```\n![product_category_name_translation_table](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/c58ac45e-65b9-41f2-aa8c-06219a828ab5)\n\n\n**The Order Table, found in the olist_orders_dataset, includes the following columns:**\n\n- order_id: a unique identifier for each order.\n- customer_id: serves as a key to the customer dataset, ensuring each order is associated with a unique customer.\n- order_status: indicates the status of the order (delivered, shipped, etc.).\n- order_purchase_timestamp: displays the timestamp of the purchase.\n- order_approved_at: denotes the timestamp when payment for the order was approved.\n- order_delivered_carrier_date: represents the timestamp when the order was handed over to the logistic partner for delivery.\n- order_delivered_customer_date: indicates the actual delivery date of the order to the customer.\n- order_estimated_delivery_date: provides the estimated delivery date communicated to the customer at the time of purchase.\n\nWe view the first few rows of the orders table using the limit from PostgreSQL.\n\n```SQL\nselect * from orders limit 10;\n```\n![orders_table1](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/d2560a3c-50a8-41a6-8e3b-264f1d45327c)\n\n![orders_table2](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/52fb6c4d-8629-4491-950c-2becb0151f39)\n\n\n**The Review Table, found in the olist_order_reviews_dataset, contains the following columns:**\n\n- review_id: a unique identifier for each review.\n- order_id: a unique identifier for each order.\n- review_score: a rating ranging from 1 to 5 provided by the customer in a satisfaction survey.\n- review_comment_title: the title of the comment left by the customer in Portuguese.\n- review_comment_message: the message of the comment left by the customer in Portuguese.\n- review_creation_date: indicates the date the satisfaction survey was sent to the customer.\n- review_answer_timestamp: denotes the timestamp of the customer's response to the satisfaction survey.\n\n```SQL\nselect * from order_reviews limit 10;\n```\n![order_reviews](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/8b44ae16-3ca8-4c1f-a295-4b65ef959d8e)\n\n\n**The Order Payment Table, found in the olist_order_payments_dataset, includes the following columns:**\n\n- order_id: a unique identifier for each order.\n- payment_sequential: indicates the sequence number for payments made by a customer for an order.\n- payment_type: specifies the method of payment selected by the customer.\n- payment_installments: denotes the number of installments chosen by the customer for payment.\n- payment_value: represents the value of the transaction.\n\n```SQL\nselect * from order_payments limit 10;\n```\n![order_payments](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/2b6cd22a-a38f-4659-8d80-b1f6286d1a53)\n\n\n**The Seller Table, found in the olist_sellers_dataset, contains the following columns:**\n\n- seller_id: a unique identifier for each seller.\n- seller_zip_code: the first 5 digits of the seller's zip code.\n- seller_city: the name of the city where the seller is located.\n- seller_state: the state where the seller is located.\n\n```SQL\nselect * from sellers limit 10;\n```\n![sellers](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/d7392d3f-e172-4cc4-ba2b-c6a8dd62d456)\n\n\n**The Customer Table, found in the olist_customers_dataset, includes the following columns:**\n\n- customer_id: serves as a reference key to the orders dataset, with each order having a unique customer_id.\n- customer_unique_id: provides a distinct identifier for each customer. This ensures that repeat purchases made by the same customer can be identified within the dataset. Otherwise, each order would appear associated with a different customer.\n\n- customer_zip_code_prefix: denotes the first five digits of the customer's zip code.\n- customer_city: specifies the name of the customer's city.\n- customer_state: indicates the state where the customer is located.\n\n```SQL\nselect * from customers limit 10;\n```\n![customers](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/0f4b1ce5-0c9c-4b07-9e85-f031be5632e4)\n","metadata":{}},{"cell_type":"markdown","source":"### EDA involved in exploring the Olist dataset to answer key questions for order analysis are as such:\n\n- What does the distribution of orders look like on a monthly basis?\n- How have the order statuses \"unavailable\" and \"canceled\" varied over the years 2016-2018?\n- How has the order status \"delivered\" varied over the years 2016-2018?\n- After examining the order counts broken down by product category. Which categories stand out during special occasions such as Valentine's Day?\n- What is the distribution of order counts based on both the days of the week (e.g., Monday, Thursday) and the days of the month (e.g., 1st, 2nd, etc.)? Additionally, how do these patterns differ across different days of the week and dates within a month?\n\n  \n### EDA involved in exploring the Olist dataset to answer key questions for customer analysis is as such:\n\n- Which cities have customers who make the most purchases? Determine the city where each customer places the highest number of orders and conduct the analysis accordingly.\n\n\n### EDA involved in exploring the Olist dataset to answer key questions for seller analysis are as such:\n\n- Who are the top 5 sellers that deliver orders to customers most efficiently? Bring the top 5 sellers who deliver orders to customers most efficiently? Analyze and interpret their order counts along with the reviews and ratings of their products.\n- Which sellers sell products across a wider range of categories? Do sellers with a wider range of categories also have higher order counts?\n\n\n### EDA involved in exploring the Olist dataset to answer key questions for payment analysis are as such:\n\n- In which regions do users that have more installments for payment primarily live?\n- What is the breakdown of successful orders and total successful payment amounts based on payment methods?\n- What is the distribution of orders based on payment method, specifically comparing single payments versus installments across different product categories? Which categories are most frequently paid for in installments?","metadata":{}},{"cell_type":"markdown","source":"## Data Analysis\n\n```SQL\nSELECT * from orders limit 10;\n``` \nTo start, we view the first 10 orders of the dataset.\n\n```SQL\nSELECT count(order_id),\n\tEXTRACT(MONTH from order_approved_at) AS approved_month\nFROM orders\nGROUP BY approved_month\nORDER BY approved_month;\n```\n\nWe can now see the distribution of orders on a monthly basis.\n\nWe first start with importing the relevant libraries.\n\n``` Python\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n```\nWith the help of Matplotlib alongside the Seaborn library, we employ the barplot() function to visualize the distribution of orders across different months. Additionally, we leverage functions from the Matplotlib library to enhance the aesthetic appeal of the plot. As a result, we obtain a clear representation of the monthly order distribution.\nThen we import our CSV file to our Jupyter Notebook. Afterward, we remove any rows containing missing values (NaN values). This step ensures data cleanliness and prevents potential issues during analysis.\n\n``` Python\nmonthly_order_data= pd.read_csv(r\"C:...\\monthly_order.csv\")\nmonthly_order_data.dropna(inplace=True)\nmonthly_order_data.approved_month=monthly_order_data.approved_month.astype(int)\n```\nAt last, we use the barplot() function to visualize the distribution of orders across different months.\n\n``` Python\nplt.figure(figsize=(15, 8))\nsns.barplot(x='approved_month', y='count', data=monthly_order_data.astype(int), palette=['brown'], linewidth=2, ci=None)\nplt.title('Monthly Orders Over Time', color='white')\nplt.xlabel('Months', color='white')\nplt.ylabel('Number of Orders', color='white')\nplt.show()\n```\n\n![monthly_orders](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/3ee4033a-9a28-4726-80f5-e5aaeeec034a)\n\n\nThe query below aims to analyze the distribution of orders based on their status (e.g., delivered, shipped, processed) and the month in which they were approved. It retrieves the count of orders, along with their respective order status and the month in which they were approved. We did not filter explicitly for the order_status by using SQL, we found the order status friction of the monthly orders only. \n\n ``` SQL\nSelect count(order_id), order_status,\n\t\textract(month from order_approved_at) as approved_month\nfrom orders\ngroup by order_status, approved_month\norder by order_status desc, approved_month desc;\n```\n\nWe will now filter the data for orders with order status 'unavailable' or 'cancelled' with Python. And we will employ a barplot() function to visualize the unavailable or cancelled orders by month on the x-axis. The frequency of orders will be depicted on the y-axis.\n\n``` Python\nunavailable_or_cancelled_orders = order_status_distribution[(order_status_distribution['order_status'] == 'unavailable') | (order_status_distribution['order_status'] == 'cancelled')]\nmonths = sorted(unavailable_or_cancelled_orders['approved_month'].unique())\nplt.figure(figsize=(12, 6))\nplt.bar(unavailable_or_cancelled_orders['approved_month'], unavailable_or_cancelled_orders['count'], color='brown', linewidth=3)\nplt.xticks(months, rotation=0, fontsize=10)\nplt.title('Monthly Friction of Unavailable or Cancelled Orders')\nplt.xlabel('Approved Month')\nplt.ylabel('Number of Orders')\nplt.tight_layout()\nplt.show()\n```\n\n![Q1](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/9d0f34a3-f381-4061-993f-3105067674eb)\n\n\n\n\nWe will apply the same filter with orders where the order status is delivered. We will again use a barplot() function to visualize our graph. \n\n``` Python\n\ndelivered_orders = delivered_orders.dropna(subset=['approved_month'])\ndelivered_orders['approved_month'] = delivered_orders['approved_month'].astype(int)\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x='approved_month', y='count', data=delivered_orders, color='green', ci=None)\nplt.title('Monthly Friction of Delivered Orders')\nplt.xlabel('Months')\nplt.ylabel('Number of Orders')\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.tight_layout()\nplt.show()\n```\n\n![Q1_2](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/5a270ceb-c1c5-4068-a348-64da3202ab77)\n\n\nAfter we examined the order statuses of the monthly orders, we will now examine the categories that stand out during special occasions such as Valentine's Day. We took days between the first of February and the 13th of February to examine the product categories until Valentine's Day on the 14th of February. \n\n``` SQL\nSELECT \n    COUNT(o.order_id) AS order_count,\n    t.product_category_name_english,\n    DATE(o.order_approved_at) AS approved_date,\n    EXTRACT(YEAR FROM o.order_approved_at) AS approved_year \nFROM \n    orders AS o\nLEFT JOIN \n   order_items AS b ON o.order_id = b.order_id\nLEFT JOIN \n    products AS p ON b.product_id = p.product_id\nLEFT JOIN \n    product_category_name_translation AS t ON p.product_category_name = t.product_category_name\nWHERE \n    (EXTRACT(MONTH FROM o.order_approved_at) = 2 AND EXTRACT(DAY FROM o.order_approved_at) BETWEEN 1 AND 13)\nGROUP BY \n    approved_date, approved_year, product_category_name_english\nORDER BY  order_count desc\nlimit 15\n;\n```\nOnce we imported our CSV file to our Jupyter Notebook, we used a barplot() to visualize the top categories that were popular during Valentine's Day shopping period.\n\n``` Python\nproduct_category_valentines_day= pd.read_csv(r\"C:...\\Desktop\\product_category_valentines_day.csv\")\nproduct_category_valentines_day\n\nplt.figure(figsize=(12, 8))\nsns.barplot(x='product_category_name_english', y='order_count' ,data=product_category_valentines_day, ci=None)\nplt.title('Product Distribution by Valentines Day')\nplt.xlabel('Category')\nplt.ylabel('Number of Products')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n```\n\n![valentinesday](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/eb327fed-9afd-46cc-933c-aff5c387e9f1)\n\n\nIn the following query, we analyzed the number of orders based on the days of the week (e.g., Monday, Thursday).\n``` SQL\nSelect count(order_id) as order_count,\nto_char(order_purchase_timestamp, 'Day') as approved_day\nfrom orders\ngroup by approved_day\norder by approved_day;\n``` \nWe also examined the order counts by the days of the month (e.g., 1st, 2nd, etc.).\n\n``` SQL\nSelect count(order_id) as order_count, \nextract(day from order_purchase_timestamp) as days_of_the_month\nfrom orders\ngroup by approved_day, days_of_the_month\norder by approved_day , days_of_the_month \n;\n```\n\nAfter importing our CSV file into Jupyter Notebook, we can proceed with visualizing our data. Depending on the nature of our analysis, we will utilize various visualization libraries such as Matplotlib, Seaborn, or Plotly.\n\n``` Python\ndays_order_count = pd.read_csv(r\"C:...\\Desktop\\days_order_count.csv\")\ndays_order_count\n```\n\nFor this visualization, we used a pie chart from Plotly to visualize the distribution of order counts by days of the week. \n\n``` Python\nplt.figure(figsize=(10, 6))\nplt.pie(days_order_count['order_count'], labels=days_order_count['approved_day'], autopct='%1.1f%%', startangle=140)\nplt.title('Order Count by Days of the Week')\nplt.axis('equal')  \nplt.show()\n```\n\n![pie](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/39364569-80df-486e-93ac-e2ae2c892a9e)\n\n\n\nBefore creating visualizations for the days of the month order count, we needed to perform data preprocessing tasks. As such as cleaning the data to make it suitable for visualization.\n\n``` Python\ndays_of_the_month_order_count= pd.read_csv(r\"C:...\\Desktop\\days_of_the_month_ordercount.csv\")\n\ndays_of_the_month_order_count_cleaned= days_of_the_month_order_count.dropna()\nprint(days_of_the_month_order_count_cleaned)\n```\n\n``` Python\nplt.figure(figsize=(15, 8))\nsns.lineplot(x='days_of_the_month', y='order_count', data=days_of_the_month_order_count_cleaned, ci=None, marker='o', markersize=8) \nplt.title('Order Count by Days of the Month')\nplt.xlabel('Days of the Month ')\nplt.ylabel('Number of Orders')\nplt.xticks(days_of_the_month_order_count_cleaned['days_of_the_month'])\nplt.show()\n```\nThe line chart below displays the distribution of order counts across different days of the month. Each bar represents the number of orders received on a specific day of the month. \n\n![order_days_monthly](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/5971152e-21be-4176-be77-dbccd3a7fd61)\n\n\nFrom the visualization, we can observe some patterns:\n- There is some variation in the number of orders throughout the month, with the 3rd, 4th, 5th, and 16th days of the month having higher order counts than others.\n- The 24th and 25th days peak in order counts, indicating days of increased sales activity.\n- The last day of the month exhibits the lowest order count, suggesting no or closer to zero order placement.\n- Overall, there seems to be some variability in order volumes across different days of the month, which could be influenced by factors such as promotions, seasonality, or customer behavior. Further analysis could be conducted to identify any underlying trends or patterns driving these fluctuations in order counts on different days of the month.\n\n\nNext, we will delve deeper into customer analysis by identifying the cities with the highest number of shoppers.\n\n``` SQL\nWITH order_counts AS (\n    SELECT \n        o.customer_id,\n        c.customer_city,\n        COUNT(o.order_id) AS order_count\n    FROM \n        orders AS o \n    LEFT JOIN \n        customers AS c ON c.customer_id = o.customer_id\n    GROUP BY \n        o.customer_id,\n        c.customer_city\n), \ncustomer_city_rn AS (\n    SELECT \n        ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_count DESC) AS rn,\n        customer_id,\n        customer_city\n    FROM \n        order_counts\n),\ncustomer_city AS (\n    SELECT \n        customer_id,\n        customer_city\n    FROM \n        customer_city_rn\n    WHERE \n        rn = 1\n)\nSELECT \n    cc.customer_city,\n    COUNT(o.order_id)\nFROM \n    orders AS o\nLEFT JOIN \n    customer_city AS cc ON o.customer_id = cc.customer_id\nGROUP BY \n    cc.customer_city\nORDER BY \n    COUNT(o.order_id) DESC;\n```\n\n```Python\nTop_orders_per_city= pd.read_csv(r\"C:...\\Desktop\\top_orders_per_city.csv\")\nTop_orders_per_city\n\nplt.figure(figsize=(20,8))\nsns.barplot(x='customer_city', y='count', data=Top_orders_per_city)\nplt.title('City-wise Top Orders')\nplt.xlabel('Customer City')\nplt.ylabel('Order Count')\n```\nWe will again employ a barplot() function from the Seaborn to visualize the list of cities and the count of customer orders in each city. \n\n![top_orders_per_city](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/5b3d438b-ad0d-4511-9eb6-7db06939300d)\n\nHere is the number of orders per city:\n\nSao Paulo: 15,540 orders\nRio de Janeiro: 6,882 orders\nBelo Horizonte: 2,773 orders\nBrasilia: 2,131 orders\nCuritiba: 1,521 orders\nCampinas: 1,444 orders\nPorto Alegre: 1,379 orders\nSalvador: 1,245 orders\nGuarulhos: 1,189 orders\nSao Bernardo do Campo: 938 orders\n\nThis indicates that Sao Paulo has the highest number of orders, followed by Rio de Janeiro, Belo Horizonte, and other cities in descending order of order count.\n\n\nNext, with the following query, we will be able to identify sellers who have a track record of delivering orders quickly while maintaining satisfactory average review scores from customers.\n\n``` SQL\nWITH fastest_delivered_products AS (\n    SELECT \n        oi.seller_id,\n        (o.order_delivered_customer_date - o.order_purchase_timestamp) AS delivery_time_days\n    FROM \n        orders o\n    LEFT JOIN \n        order_items oi ON oi.order_id = o.order_id\n)\nSELECT \n    f.seller_id,\n    COUNT(DISTINCT oi.order_id) AS order_count,\n    AVG(f.delivery_time_days) AS avg_delivery_time,\n    AVG(rw.review_score) AS avg_review_score\nFROM \n    fastest_delivered_products f\nJOIN \n    order_items oi ON oi.seller_id = f.seller_id\nLEFT JOIN \n    order_reviews rw ON rw.order_id = oi.order_id\nGROUP BY\n    f.seller_id\nHAVING \n    AVG(f.delivery_time_days) IS NOT NULL \n    AND COUNT(DISTINCT oi.order_id) > 15\nORDER BY \n    avg_delivery_time\nLIMIT 5;\n```\nWe plot with a bar chart for the top 5 fastest delivery sellers by their order count.\n\n```Python\nfastest_delivery_sellers= pd.read_csv(r\"C:...\\Desktop\\fastest_delivery_sellers.csv\")\nfastest_delivery_sellers\n\nplt.figure(figsize=(15, 8))\nsns.catplot(x='customer_state', y='count', data=highest_number_of_installment_payments_reside, kind='bar', aspect=2)\nplt.title('Analyzing Number of Payment Installments Per State')\nplt.xlabel('Customer State')\nplt.ylabel('Payment Installments')\nplt.show()\n```\n![fastest_delivery_sellers](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/38853868-0467-48af-8c5e-780f667244d0)\n\n\nNow we will also plot the top 5 fastest delivery sellers by their average review scores.\n\n```Python\ntop_sellers_by_review_score = fastest_delivery_sellers.sort_values(by='avg_review_score', ascending=False).head(5)\n\nplt.figure(figsize=(16, 7))\nsns.barplot(x='seller_id', y='avg_review_score', data=fastest_delivery_sellers, palette='viridis', ci=None)\nplt.title('Top 5 Fastest Delivery Sellers by Average Review Score')\nplt.xlabel('Seller ID')\nplt.ylabel('Average Review Score')\nplt.xticks(rotation=45)\nplt.show()\n```\n![review_score](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/cad49049-184d-4186-b678-c542570e1382)\n\n\nNext, we will check the number of categories each seller sells their products in and their corresponding order counts. \n\n```SQL\nWITH category_counts AS (\n    SELECT \n        oi.seller_id,\n        COUNT(DISTINCT oi.order_id) AS order_counts,\n        COUNT(DISTINCT p.product_category_name) AS category_count\n    FROM \n        order_items oi\n    LEFT JOIN \n        sellers s ON s.seller_id = oi.seller_id\n    LEFT JOIN \n        products p ON p.product_id = oi.product_id\n    GROUP BY \n        oi.seller_id\n)\nSELECT \n    cc.seller_id,\n    cc.order_counts,\n    cc.category_count\nFROM \n    category_counts cc\nJOIN \n    (\n        SELECT \n            seller_id,\n            MAX(category_count) AS max_category\n        FROM \n            category_counts\n        GROUP BY \n            seller_id\n    ) AS max_categories ON cc.seller_id = max_categories.seller_id \n                         AND cc.category_count = max_categories.max_category\nORDER BY \n\t\tcc.category_count desc\nLIMIT 10;\n\n```\nWe will again visualize the query by barplot() function from the Seaborn library.\n\n```Python\ncategory_counts_sellers= pd.read_csv(r\"C:...\\category_counts_sellers.csv\")\ncategory_counts_sellers\n\nplt.figure(figsize=(15,8))\nsns.barplot(x='category_count', y='order_counts', data=category_counts_sellers, palette=('GnBu_d'), ci=None)\nplt.title('Maximum Category Wise Product Sellers')\nplt.xlabel('Number of Category')\nplt.ylabel('Number of Products')\n```\n\n![max_category_sellers](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/a1b1f92b-c72c-4386-b4f5-8300b55d0014)\n\n\nThe graph indicates that there is no observable correlation between the number of product categories offered by a seller and the quantity of orders they receive.\n\n\nNow, we will conduct a customer analysis.\nWe will start with plotting the regions where users with the highest number of installment payments reside.\n\n```SQL\nWith Data as (SELECT \n\tc.customer_state,\n\tcount( distinct o.order_id) as order_count,\n    AVG(p.payment_installments) AS average_payment_installments\nFROM \n    customers c \nJOIN \n    orders o ON o.customer_id = c.customer_id\nJOIN \n    order_payments p ON p.order_id = o.order_id\nWhere p.payment_installments>12\nGROUP BY \n    p.payment_installments,\tc.customer_state\nOrder by 2 desc)\nSelect customer_state, \n\t\tcount(order_count) from Data\n\t\tgroup by 1\n\t\torder by 2 desc;\n```\nWe will again visualize our query by barplot() function from the Seaborn library.\n\n```Python\nhighest_number_of_installment_payments_reside= pd.read_csv(r\"C:...\\highest_number_of_installment_payments_reside.csv\")\nhighest_number_of_installment_payments_reside\n\nplt.figure(figsize=(15,8))\nsns.barplot(x='customer_state', y='count', data=highest_number_of_installment_payments_reside)\nplt.title('Analyzing Number of Payment Installments Per State')\nplt.xlabel('Customer State')\nplt.ylabel('Payment Installments')\nplt.show()\n```\n![payment_installments_per_state](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/7d328905-deda-4cda-b25a-b2895687596e)\n\n\nThis output represents the count of users residing in different regions where users with the highest number of installment payments reside. Each region code is followed by the count of users. For instance, \"SP\" indicates the SÃ£o Paulo region with 10 users have the highest number of installment payments. Similarly, \"RJ\" represents Rio de Janeiro with 8 users, \"MG\" represents Minas Gerais with 6 users, and so on.\n\nNext, we will calculate the number of successful orders and the total successful payment amount based on the payment method.\n```SQL\nSelect \top.payment_type,\n\t\tcount(distinct o.order_id), \n\t\tsum(case when o.order_status not in ('cancelled', 'unavailable') then op.payment_value end) as succesful_payment\nfrom order_payments op\njoin orders o on o.order_id = op.order_id\ngroup by op.payment_type \norder by op.payment_type desc\n;\n```\n\nWe will again visualize our query by barplot() function from the Seaborn library.\n```Python\npayment_type= pd.read_csv(r\"C:...\\Desktop\\payment_type_segmentatiton.csv\")\npayment_type\n\nplt.figure(figsize=(15,8))\nsns.barplot(x='payment_type', y='count', data=payment_type, ci=None, palette=['purple','yellow','orange' ,'red', 'green'])\nplt.title('Total Successful Orders Based On the Payment Method')\nplt.xlabel('Payment Method')\nplt.ylabel('Number of Successful Orders')\nplt.show()\n```\n\n![total_Succesfull_payment_method](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/72073617-b50d-473d-905a-6810fdd24474)\n\nWe can see that  the payment methods used by customers along with the corresponding order count and total successful payment amount. \n\n- \"voucher\": There are 3,866 orders made using vouchers, with a total successful payment amount of 375,539.32.\n- \"not_defined\": There are 3 orders for which the payment method is not defined, resulting in a total successful payment amount of 0.00.\n- \"debit_card\": There are 1,528 orders paid using debit cards, totaling 215,129.02 in the successful payment amount.\n- \"credit_card\": The most common payment method is a credit card, with 76,505 orders and a total successful payment amount of 12,447,417.87.\n- \"boleto\": Boletos, or bank slips, were used for 19,784 orders, amounting to 2,844,306.40 in successful payment.\n\nWe will now analyze the category-wise distribution of orders paid in single payment and in installments. We will also analyze the categories that are commonly paid in installments.\n\nQuery for orders paid in a single payment:\n```SQL\nWITH orders_single_payment AS (\n    SELECT \n        pr.product_category_name,\n        COUNT(DISTINCT o.order_id) AS order_count\n    FROM\n        orders o\n    JOIN \n        order_payments op ON op.order_id = o.order_id\n    JOIN \n        order_items oi ON oi.order_id = op.order_id\n    JOIN \n        products pr ON pr.product_id = oi.product_id\n    WHERE\n        op.payment_installments = 1\n    GROUP BY \n        pr.product_category_name\n)\nSELECT \n    'tek_cekim' AS payments,\n    product_category_name,\n    order_count\nFROM \n    orders_single_payment\nORDER BY \n    order_count DESC,\n    product_category_name DESC; \n```\n```Python\nsingle_payment_installments=pd.read_csv(r\"C:...\\Desktop\\single_installment.csv\")\nsingle_payment_installments\n\nplt.figure(figsize=(16, 8))\nsns.barplot(x='order_count', y='product_category_name', data=single_payment_installments, palette='viridis', orient='h')\nplt.title('Analyzing Category-Wise Single Installment Payments')\nplt.xlabel('Count of Orders')\nplt.ylabel('Product Category')\nplt.show()\n```\n\n![single_installment_payment](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/f70e7bd1-76aa-4003-8f4e-3c2dd014a9e6)\n\n\n\nThis graph indicates the distribution of orders paid in single-payment installments across different product categories. \n\n- \"esporte_lazer\": The category of \"Sports and Leisure\" has the highest number of orders paid in a single payment installment, with 4,299 orders.\n- \"informatica_acessorios\": Following closely, the \"Computers and Accessories\" category accounts for 4,177 orders.\n- \"beleza_saude\": The \"Beauty and Health\" category ranks third with 3,880 orders paid in a single payment installment.\n- \"cama_mesa_banho\": The category of \"Bed, Bath, and Table\" follows with 3,535 orders.\n- \"moveis_decoracao\": Lastly, the \"Furniture and Decoration\" category has 3,152 orders paid in a single payment installment.\n\n\n\n\n\nQuery for orders paid in multiple installments:\n```SQL\nWITH orders_installments AS (\n    SELECT \n        pr.product_category_name,\n        COUNT(DISTINCT o.order_id) AS order_count\n    FROM\n        orders o\n    JOIN \n        order_payments op ON op.order_id = o.order_id\n    JOIN \n        order_items oi ON oi.order_id = op.order_id\n    JOIN \n        products pr ON pr.product_id = oi.product_id\n    WHERE\n        op.payment_installments > 1\n    GROUP BY \n        pr.product_category_name\n)\nSELECT \n    'taksitli' AS payments,\n    product_category_name,\n    order_count\nFROM \n    orders_installments\nORDER BY \n    order_count DESC,\n    product_category_name DESC; \n```\nThe following graph shows the distribution of orders paid in multiple payment installments across different product categories. As such;\n\n- \"cama_mesa_banho\": There are 5,965 orders in the category of \"Bed, Bath, and Table,\" indicating that this category has the highest number of orders paid in multiple installments.\n- \"beleza_saude\": The \"Beauty and Health\" category follows closely with 5,006 orders.\n- \"relogios_presentes\": The category of \"Watches and Gifts\" has 3,794 orders paid in multiple installments.\n- \"esporte_lazer\": \"Sports and Leisure\" category accounts for 3,480 orders.\n- \"moveis_decoracao\": Lastly, the \"Furniture and Decoration\" category has 3,353 orders paid in multiple installments.\n\n```Python\nmultiple_payment_installments= pd.read_csv(r\"C:...\\Desktop\\multiple_installments.csv\")\nmultiple_payment_installments\n\nplt.figure(figsize=(16, 8))\nsns.barplot(x='order_count',y='product_category_name' ,data=multiple_payment_installments, palette='GnBu_d', orient='h')\nplt.title('Analyzing Category-Wise Multiple Installment Payments')\nplt.xlabel('Count of Orders')\nplt.ylabel('Product Category')\nplt.xticks(rotation=0)\nplt.show()\n```\n\n![multiple_payment_installment](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/90dd0db0-c537-4dd2-8e17-ca15dd4f9a9e)\n\n\n\nLastly, we will conduct the RFM (Recency, Frequency, Monetary) analysis and analyze customer behavior, and segment them into different categories based on recency, frequency, and monetary value. The segmentation can help in targeting specific customer groups with tailored marketing strategies.\n\n```SQL \nWITH rfm AS (\n  SELECT\n    customer_id,\n    MAX(invoice_date) AS max_invoice_date,\n    EXTRACT(day FROM '2011-12-09'::date - MAX(invoice_date)) AS recency,\n    COUNT(DISTINCT invoice_no) AS frequency,\n    SUM(quantity * unit_price) AS monetary\n  FROM rfm \n  WHERE quantity > 0 AND customer_id IS NOT NULL\n  GROUP BY customer_id, rfm.invoice_date\n Order by 3 Desc\n),\nscore AS (\n  SELECT\n    *,\n    NTILE(4) OVER (ORDER BY recency DESC) AS recency_score,\n    CASE\n      WHEN frequency <= 1 THEN 1\n      WHEN frequency <= 2 THEN 2\n      WHEN frequency <= 4 THEN 3\n      WHEN frequency <= 6 THEN 4\n      ELSE 5\n    END AS frequency_score,\n    NTILE(4) OVER (ORDER BY monetary ASC) AS monetary_score\n  FROM rfm\n)\nSELECT\n  *,\n  CONCAT(recency_score, frequency_score, monetary_score)::numeric AS rfm_score\nFROM score;\n\nwith recency\nas\n(\nSELECT\n\tcustomer_id,\n\tmax(invoice_date) as last_day,\n\t('2011-12-09'-max(invoice_date)::date) as recency\nFROM rfm\nWHERE customer_id is not null and invoice_no not like 'C%'\nGROUP BY customer_id\nORDER BY 3 asc\n),\nfrequency\nas\n(\nSELECT \n\tcustomer_id,\n\tcount(distinct invoice_no) as frequency\nFROM rfm\nWHERE customer_id is not null and invoice_no not like 'C%'\nGROUP BY customer_id\nORDER BY 2 desc\n),\nmonetary\nas \n(\nSELECT \n\tcustomer_id,\n\tround(sum(unit_price*quantity)::decimal,2) as monetary\nFROM rfm\nWHERE  customer_id is not null and invoice_no not like 'C%'\nGROUP BY customer_id\nORDER BY 2 desc\n),\nscores as\n(\nSELECT\n\tf.customer_id,\n\trecency,\n\tfrequency,\n\tmonetary,\n\tntile(5) over (order by recency desc) as recency_score,\n    CASE\n       WHEN frequency<10 then '1'\n       WHEN frequency >= 10 and frequency < 50 then '2'\n       WHEN frequency >= 50 and frequency < 100 then '3'\n       WHEN frequency >= 100 and frequency <= 150 then '4'\n       WHEN frequency > 150 and frequency <= 250 then '5'\n       END AS frequency_score,\n     CASE\n       WHEN monetary<5000 then '1'\n       WHEN monetary >= 5000 and monetary < 15000 then '2'\nWHEN monetary >= 15000 and monetary < 40000 then '3'\nWHEN monetary >= 40000 and monetary <= 100000 then '4'\nWHEN monetary > 100000 and monetary <= 300000 then '5'\nEND AS monetary_score\t\t\nFROM recency as r\nLEFT JOIN frequency as f\non r.customer_id=f.customer_id\nLEFT JOIN monetary as m\non r.customer_id=m.customer_id\nORDER BY 7 desc\n),\nmix_score\nas\n(\nSELECT \n\tcustomer_id,\n\trecency_score,\n\tfrequency_score,\n\tmonetary_score,\n\t(frequency_score::integer+monetary_score::integer) as mix_score\nFROM scores\nORDER BY 5\n),\nfinal_scores as \n(\nSELECT \n\tcustomer_id,\n\trecency_score,\n\tfrequency_score,\n\tmonetary_score,\n\tCASE\n\t\tWHEN mix_score=2 then '1'\n\t\tWHEN mix_score>2 and mix_score<=3 then '2'\n\t\tWHEN mix_score>3 and mix_score<=5 then '3'\n\t\tWHEN mix_score>=6 and mix_score<=7 then '4'\n\t\tELSE '5' end as mixscore\nFROM mix_score\nORDER BY mix_score desc\n)\nSELECT \n\tcustomer_id,\n\trecency_score,\n\tmixscore,\n\tCASE \n\t\tWHEN recency_score::varchar similar to  '[1-2]%' and mixscore::varchar similar to '[1-2]%' then 'Hibernating'\n\t\tWHEN recency_score::varchar similar to  '[1-2]%' and mixscore::varchar similar to '[3-4]%' then 'At_Risk'\n\t\tWHEN recency_score::varchar similar to  '[1-2]%' and mixscore::varchar similar to '[5]%' then 'Cant_Loose'\n\t\tWHEN recency_score::varchar similar to  '[3]%' and mixscore::varchar similar to '[1-2]%' then 'About_to_Sleep'\n\t\tWHEN recency_score::varchar similar to  '[3]%' and mixscore::varchar similar to '[3]%' then 'Need_Attention'\n\t\tWHEN recency_score::varchar similar to  '[4]%' and mixscore::varchar similar to '[1]%' then 'Promising'\n\t\tWHEN recency_score::varchar similar to  '[5]%' and mixscore::varchar similar to '[1]%' then 'New_Customers'\n\t\tWHEN recency_score::varchar similar to  '[4-5]%' and mixscore::varchar similar to '[2-3]%' then 'Potential_Loyaltist'\n\t\tWHEN recency_score::varchar similar to  '[3-4]%' and mixscore::varchar similar to '[4-5]%' then 'Loyal_Customers'\n\t\tWHEN recency_score::varchar similar to  '[5]%' and mixscore::varchar similar to '[4-5]%' then 'Champions'\n\t\tEND AS customer_segmentation\nFROM final_scores \nORDER BY 2 desc;\n```\n\nWe will visualize our query using the barplot() function from the Seaborn Library.\n\n```Python\nRFM_Analysis= pd.read_csv(r\"C...\\Desktop\\RFM.csv\")\nRFM_Analysis\n\nplt.figure(figsize=(10, 5))\npercentage = (RFM_Analysis['customer_segmentation'].value_counts(normalize=True) * 100).reset_index(name='Percentage')\ng = sns.barplot(x=percentage['Percentage'], y=percentage['index'], data=percentage, palette=\"viridis\")\nsns.despine(bottom=True, left=True)\nfor i, v in enumerate(percentage['Percentage']):\n    g.text(v, i + 0.20, \"  {:.2f}\".format(v) + \"%\", color='black', ha=\"left\")\ng.set_ylabel('Segmentation')\ng.set(xticks=[])\nplt.show()\n```\n\n![RFM](https://github.com/denizyennerr/Brazilian_E-commerce_Analysis/assets/160275199/acecce93-fc18-42bd-bd24-3b65a12daf9f)\n","metadata":{}},{"cell_type":"markdown","source":"\n### Based on the analysis of customer segments derived from the query results, the following insights and CRM strategies can be outlined:\n\n**Hibernating (39.82%):*\n- Customers that have low spending but made infrequent purchases in the past.\n- As a CRM Strategy sending out offers as standard communication and relevant product deals to promote repetitive purchases.\n\n**About to Sleep (19.73%):*\n- Recent buyers who are hesitant about future purchases from competitors or the company.\n- As a CRM Strategy, provide them with product recommendations based on their behavior, send out promotional campaigns for a limited time, and emphasize the benefits of purchasing from the company.\n\n**Promising (17.03%):*\n- Customers who can become loyal because of their moderate spending and recent engagement.\n- As a CRM Strategy, capture these customers with exclusive offers, personalized recommendations, and incentives to encourage brand loyalty and repeat purchases.\n\n\n**New Customers (13.83%):*\n- These are recently gained customers who have not yet established long-term engagement with the company.\n- As a CRM Strategy, provide a warm welcome pack with personalized onboarding messages, introductory offers, and guidance on product selection to encourage future interactions and repeat purchases.\n\n\n**Potential Loyalist (8.57%):*\n- They are recent buyers with multiple purchases and good spending habits.\n- As a CRM Strategy, a loyalty program can be offered, and multiple purchases can retain engagement through personalized recommendations.\n\n**Champions (0.48%):*\n- Top-tier customers with significant spending and loyalty.\n- As a CRM Strategy, sustain personalized communication, promote exclusive benefits, and offer VIP treatment to strengthen advocacy and loyalty.\n\n**Need Attention (0.25%):*\n- Customers who have made recent purchases but show signs of hesitation or uncertainty.\n- As a CRM Strategy, reach out to these customers to address any concerns or questions they may have, target communications, and provide securitization to encourage continued engagement and loyalty.\n\n**At Risk (0.18%):*\n- These customers possess potential disengagement who used to purchase frequently but have not made recent purchases.\n- As a CRM Strategy, offer attractive deals, reconnect with personalized communications, and emphasize the value of continued patronage.\n\n**Loyal Customers (0.09%):*\n- High-value customers who make frequent purchases.\n- As a CRM Strategy, provide tailored product recommendations, engage in personalized communication, avoid mass mailing of offers, and offer product reviews.","metadata":{}},{"cell_type":"markdown","source":"## Results and Findings\n\n1. Order Count by Days of the Week:\n- The distribution of orders across different days of the week shows variations, with certain days having higher order volumes in comparison to others.\n- A separate analysis can explain the main factor influencing daily order volumes, including external sources such as promotional campaigns, customer behavior patterns, and holidays.\n\n2. Monthly Orders for Delivered Orders:\n- As can be depicted from the bar chart the distribution of monthly delivery orders is represented and provides insights into the volume of orders processed over time.\n- Peaks and troughs in order volumes may coincide with seasonal trends, as such marketing campaigns or other factors that determine the customer's behavior.\n\n3. Top 5 Fastest Delivery Sellers by Average Review Score:\n- The top five sellers did this research based on their average shipment times and reviews.\n- Amazon transactions are affected by sellers with shorter delivery times and have the advantage of higher review scores, more customer attraction and retention.\n\n\n4.  Category-Wise Distribution of Payment Installments:\n- The analysis shows the distribution of payment installments across different product categories.\n- Understanding payment preferences can help optimize payment processing systems and tailor promotional offers to match customer preferences.\n\n\n5. Top Regions with Highest Number of Installment Payments:\n- Businesses can view their marketing efforts by identifying regions with the highest number of installment payments, according to their customer's needs.\n\n\n6. Distribution of Other Orders in Single and Multiple Installments:\n- The analysis examines the difference in the distribution of payments between payment orders in a single payment and multiple installments across various product categories.\n- Insights from this analysis can inform inventory management and pricing strategies to accommodate different payment preferences.\n\n\n7. Customer Segmentation Analysis:\n- Through RFM (Recency, Frequency, Monetary) analysis customers are divided into distinct groups, depending on their transactional behavior.\n- Customer groups like \"Champion,\" \"Promising\" and \"New Customers\" offer valuable insights to marketing and sales departments for targeted marketing and customer relationship management strategies.\n\n\n8. Customer Segmentation Results:\n- The segmentation analysis segments the customers into different groups based on their RFM score and their behavioral patterns which help to get a better understanding of the most loyal customers are for the company along with the retention rate of the lost customers.\n- On every customer segment we process an individual marketing and retaining tactic that should aim at gaining customer engagement and profitability.\n\n\n- These findings provide valuable insights for decision-making across various aspects of e-commerce operations, ranging from marketing to service, logistics as well as product management. Further exploration and refinement of these insights can lead to ameliorated customer satisfaction, increased customer retention, and improved business success.\n\n\n### Limitations\n- The digital business market in Brazil is an incredibly vital and dynamic industry. The market is influenced by various factors such as regulatory changes, technological innovations,  and competitiveness. There may be some changes in the past that could not cover these dynamic shifts completely.\n- In this way, the dataset emphasizes the transactions inside the Olist platform instead of the market as a whole about e-commerce Brazil. It might need to include additional data from various platforms to identify the competitive dynamics or market share.\n\n\n## Recommendations\n- Furthermore, RFM analysis is used to statistically evaluate the profitability of individual segments over a long period. On top of the RFM analysis, a customer lifetime value can be used to measure the long-term profitability of different customer segments. Therefore, marketers can better understand and shape their customer segmentation strategies and prioritize marketing endeavors to capture their target market accordingly.\n\n  \n### References\n\n1. [PostgreSQL.org] (https://www.postgresql.org/docs/current/datatype-datetime.html)\n2. Olist Store Ecommerce Dataset. Retrieved from [https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce] \n4. Brazilian Institute of Geography and Statistics (IBGE), (1972). Brazilian Zip Code Geolocation Dataset. Retrieved from [https://www.ibge.gov.br/en/]\n5. Pagan Research [https://paganresearch.io/company/olist]\n6. VINICIUS DUZAC CERUTTI(2022) Retrieved from: [https://www.kaggle.com/code/ceruttivini/rfm-segmentation-and-customer-analysis]\n7. KHUSHEE KAPOOR(2022) Retrieved from: [https://www.kaggle.com/code/khusheekapoor/relational-database-eda-data-preparation]","metadata":{}}]}